{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44e3973",
   "metadata": {},
   "source": [
    "## ANN Regression & Functional APIs\n",
    "ANN model to predict the price of a property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594c050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3925fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "house = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1f16c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedHouseVal']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ba68d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddffb154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(house.data, \n",
    "                                                              house.target, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f7f4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d46ee7",
   "metadata": {},
   "source": [
    "scaler is trained on training data only because we do not want info from test set or validation set to influence model training. scaler will find values from the training data to subtract as a mean & to divide as a std dev. scaler will use these values to standardise validation & test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e6f4f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eae9bf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f9a9a",
   "metadata": {},
   "source": [
    "Since this is a regression problem, we will have a single output neuron w/o any activation function. A single neuron because we want a continuous value as o/p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfe8cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Dense, concatenate\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b91f92f",
   "metadata": {},
   "source": [
    "We need to provide input_shape in the 1st layer of the network.<br>\n",
    "input_shape = number of independent vars in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d2ead5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = Sequential()\n",
    "model_A.add(Dense(30, activation='relu', input_shape = [8]))\n",
    "# model_A.add(Dense(30, activation='relu', input_shape = x_train.shape[1:]))\n",
    "model_A.add(Dense(30, activation='relu'))\n",
    "model_A.add(Dense(1))\n",
    "\n",
    "model_A.compile(optimizer = SGD(learning_rate = 1e-3),\n",
    "              loss = \"mean_squared_error\",\n",
    "              metrics = ['mae'])\n",
    "# mae is the mean absolute error = |predicted value - actual value|\n",
    "# mean_squared_error = mae^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "667ecd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=x_train.shape[1:])\n",
    "hidden1 = Dense(30, activation='relu')(input_)\n",
    "hidden2 = Dense(30, activation='relu')(hidden1)\n",
    "concat = concatenate([input_,hidden2])\n",
    "output = Dense(1)(concat)\n",
    "model_B = Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "model_B.compile(optimizer = SGD(learning_rate = 1e-3),\n",
    "                loss = \"mean_squared_error\",\n",
    "                metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b5553e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb_A = keras.callbacks.ModelCheckpoint(\"HousePrice_model_A.h5\", save_best_only=True)\n",
    "checkpoint_cb_B = keras.callbacks.ModelCheckpoint(\"HousePrice_model_B.h5\", save_best_only=True)\n",
    "early_stopping_cb_A = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "early_stopping_cb_B = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc97d3f",
   "metadata": {},
   "source": [
    "keras stores the weights & biases in memory. if we re-run the model.fit() 2 times, that will be similar to running model.fit() with 40 epochs. in the re-run, it will start with 21st epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8dd5191",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.9606 - mae: 1.0113 - val_loss: 0.9678 - val_mae: 0.6920\n",
      "Epoch 2/20\n",
      "102/363 [=======>......................] - ETA: 0s - loss: 0.8186 - mae: 0.6780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geetika singh\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7424 - mae: 0.6450 - val_loss: 0.9821 - val_mae: 0.6114\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6489 - mae: 0.5974 - val_loss: 0.6635 - val_mae: 0.5668\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5997 - mae: 0.5700 - val_loss: 0.5415 - val_mae: 0.5438\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5624 - mae: 0.5493 - val_loss: 0.5076 - val_mae: 0.5222\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5312 - mae: 0.5326 - val_loss: 0.5285 - val_mae: 0.5097\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5057 - mae: 0.5175 - val_loss: 0.4910 - val_mae: 0.4959\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4843 - mae: 0.5050 - val_loss: 0.4430 - val_mae: 0.4798\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4663 - mae: 0.4937 - val_loss: 0.4620 - val_mae: 0.4731\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4515 - mae: 0.4851 - val_loss: 0.4289 - val_mae: 0.4628\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4397 - mae: 0.4775 - val_loss: 0.4040 - val_mae: 0.4584\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4300 - mae: 0.4716 - val_loss: 0.4075 - val_mae: 0.4529\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4217 - mae: 0.4669 - val_loss: 0.3876 - val_mae: 0.4489\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4148 - mae: 0.4622 - val_loss: 0.3851 - val_mae: 0.4468\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4090 - mae: 0.4590 - val_loss: 0.3824 - val_mae: 0.4425\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4042 - mae: 0.4558 - val_loss: 0.3791 - val_mae: 0.4402\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3997 - mae: 0.4531 - val_loss: 0.3704 - val_mae: 0.4359\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3957 - mae: 0.4505 - val_loss: 0.3670 - val_mae: 0.4332\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3920 - mae: 0.4480 - val_loss: 0.3745 - val_mae: 0.4335\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3892 - mae: 0.4459 - val_loss: 0.3788 - val_mae: 0.4347\n"
     ]
    }
   ],
   "source": [
    "history_A = model_A.fit(x_train, y_train, epochs=20, \n",
    "                      validation_data=(x_val,y_val),\n",
    "                      callbacks = [checkpoint_cb_A, early_stopping_cb_A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "057e8444",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.6393 - mae: 1.1665 - val_loss: 0.7854 - val_mae: 0.6227\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6627 - mae: 0.5945 - val_loss: 0.6803 - val_mae: 0.5676\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6072 - mae: 0.5657 - val_loss: 0.5677 - val_mae: 0.5396\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5703 - mae: 0.5470 - val_loss: 0.5302 - val_mae: 0.5299\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5465 - mae: 0.5338 - val_loss: 0.5248 - val_mae: 0.5147\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5224 - mae: 0.5242 - val_loss: 0.4770 - val_mae: 0.5018\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5083 - mae: 0.5154 - val_loss: 0.4632 - val_mae: 0.4925\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4946 - mae: 0.5076 - val_loss: 0.4763 - val_mae: 0.4875\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4804 - mae: 0.5013 - val_loss: 0.4412 - val_mae: 0.4802\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4698 - mae: 0.4955 - val_loss: 0.4288 - val_mae: 0.4707\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4613 - mae: 0.4892 - val_loss: 0.4832 - val_mae: 0.4783\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4533 - mae: 0.4858 - val_loss: 0.4129 - val_mae: 0.4620\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4469 - mae: 0.4819 - val_loss: 0.4160 - val_mae: 0.4624\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4421 - mae: 0.4782 - val_loss: 0.4125 - val_mae: 0.4601\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4359 - mae: 0.4753 - val_loss: 0.4026 - val_mae: 0.4548\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4315 - mae: 0.4724 - val_loss: 0.4002 - val_mae: 0.4530\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4273 - mae: 0.4697 - val_loss: 0.4361 - val_mae: 0.4539\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4244 - mae: 0.4681 - val_loss: 0.4345 - val_mae: 0.4496\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4197 - mae: 0.4649 - val_loss: 0.4010 - val_mae: 0.4455\n"
     ]
    }
   ],
   "source": [
    "history_B = model_B.fit(x_train, y_train, epochs=20, \n",
    "                        validation_data=(x_val, y_val),\n",
    "                        callbacks = [checkpoint_cb_B, early_stopping_cb_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841114ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_A.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9447b6",
   "metadata": {},
   "source": [
    "this graph is still going down, means that if we run some more epochs, it will further decrease the losses & improve accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc347316",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_B.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a07d9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3949 - mae: 0.4497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39493411779403687, 0.44973522424697876]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A = load_model(\"HousePrice_model_A.h5\")\n",
    "model_A.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e1c1f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4271 - mae: 0.4687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42712682485580444, 0.4686586260795593]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B = keras.models.load_model(\"HousePrice_model_B.h5\")\n",
    "model_B.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cc65470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.61997306],\n",
       "       [1.5508323 ],\n",
       "       [3.405706  ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_A.predict(x_test[:3])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4cdabeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.477  , 0.458  , 5.00001])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def3e82e",
   "metadata": {},
   "source": [
    "here, normal sequential MLP model is performing better than wide MLP model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
